<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2025-07-01T22:42:21+02:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Omer Yildiran</title><subtitle>PhD Candidate in Cognition &amp; Perception at NYU | Time perception, sensory modeling, adaptive learning</subtitle><author><name>Omer Yildiran</name></author><entry><title type="html">How to run Jekyll my version</title><link href="http://localhost:4000/2025/07/01/myHowTo.html" rel="alternate" type="text/html" title="How to run Jekyll my version" /><published>2025-07-01T00:00:00+02:00</published><updated>2025-07-01T00:00:00+02:00</updated><id>http://localhost:4000/2025/07/01/myHowTo</id><content type="html" xml:base="http://localhost:4000/2025/07/01/myHowTo.html"><![CDATA[<p>Hello this is my:</p>
<h1 id="how-to-run-my-site-short-terminal-arguments">How to run my site short terminal arguments</h1>
<p>chruby ruby-3.4.1<br />
ruby -v<br />
cd ofyWeb<br />
bundle exec jekyll serve</p>]]></content><author><name>Omer Yildiran</name></author><summary type="html"><![CDATA[Hello this is my: How to run my site short terminal arguments chruby ruby-3.4.1 ruby -v cd ofyWeb bundle exec jekyll serve]]></summary></entry><entry><title type="html">Models of Bimodal Duration Estimation</title><link href="http://localhost:4000/2025/07/01/Models-of-Bimodal-Duration-Discrimination-new.html" rel="alternate" type="text/html" title="Models of Bimodal Duration Estimation" /><published>2025-07-01T00:00:00+02:00</published><updated>2025-07-01T00:00:00+02:00</updated><id>http://localhost:4000/2025/07/01/Models%20of%20Bimodal%20Duration%20Discrimination%20new</id><content type="html" xml:base="http://localhost:4000/2025/07/01/Models-of-Bimodal-Duration-Discrimination-new.html"><![CDATA[<h1 id="model-coding">Model Coding:</h1>

<p>Created: June 18, 2025 6:09 PM
Tags: article note</p>

<h1 id="1--unimodal">1- Unimodal</h1>

<h3 id="11-measurement">1.1 Measurement</h3>

<p><img src="/assets/images/modelsOfbimodal/imageHo.png" alt="imageHo" /></p>

\[m=N(s,\sigma^2)\]

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># unimodal measurements
</span><span class="k">def</span> <span class="nf">unimodalMeasurements</span><span class="p">(</span><span class="n">sigma</span><span class="p">,</span> <span class="n">S</span><span class="p">):</span>
    <span class="c1"># P(x|s) # generate measurements from a normal distribution
</span>    <span class="n">m</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">normal</span><span class="p">(</span><span class="n">S</span><span class="p">,</span> <span class="n">sigma</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="mi">10000</span><span class="p">)</span>  <span class="c1"># true duration is S seconds
</span>    <span class="k">return</span> <span class="n">m</span>

</code></pre></div></div>

<h3 id="12-likelihood"><strong>1.2 Likelihood</strong></h3>

\[p(m|s)=\frac{1}{\sqrt{2\pi} \sigma}\exp(-\frac{(m-s)^2}{2\sigma^2})\]

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">gaussianPDF</span><span class="p">(</span><span class="n">m</span><span class="p">,</span><span class="n">s</span><span class="p">,</span><span class="n">sigma</span><span class="p">):</span>
    <span class="nf">return </span><span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">np</span><span class="p">.</span><span class="n">pi</span><span class="p">)</span><span class="o">*</span><span class="n">sigma</span><span class="p">))</span><span class="o">*</span><span class="n">np</span><span class="p">.</span><span class="nf">exp</span><span class="p">(</span><span class="o">-</span><span class="p">((</span><span class="n">x</span><span class="o">-</span><span class="n">s</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="p">(</span><span class="n">sigma</span><span class="o">**</span><span class="mi">2</span><span class="p">)))</span>

<span class="c1"># likelihood function
</span><span class="k">def</span> <span class="nf">likelihood</span><span class="p">(</span><span class="n">S</span><span class="p">,</span> <span class="n">sigma</span><span class="p">):</span>
    <span class="c1"># P(m|s) # likelihood of measurements given the true duration
</span>    <span class="n">m</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="nf">linspace</span><span class="p">(</span><span class="n">S</span> <span class="o">-</span> <span class="mi">4</span><span class="o">*</span><span class="n">sigma</span><span class="p">,</span> <span class="n">S</span> <span class="o">+</span> <span class="mi">4</span><span class="o">*</span><span class="n">sigma</span><span class="p">,</span> <span class="mi">500</span><span class="p">)</span>
    <span class="n">p_x</span><span class="o">=</span><span class="nf">gaussianPDF</span><span class="p">(</span><span class="n">m</span><span class="p">,</span><span class="n">S</span><span class="p">,</span><span class="n">sigma</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">x</span><span class="p">,</span> <span class="n">p_x</span>

</code></pre></div></div>

<p>1.2.1 <strong>Plot Likelihoods analytically</strong></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">plotLikelihood</span><span class="p">(</span><span class="n">S</span><span class="p">,</span><span class="n">sigma</span><span class="p">):</span>
    <span class="n">x</span><span class="p">,</span> <span class="n">p_x</span> <span class="o">=</span> <span class="nf">likelihood</span><span class="p">(</span><span class="n">S</span><span class="p">,</span> <span class="n">sigma</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">p_x</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">Likelihood Function</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Measurement $m$</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Probability Density</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sh">'</span><span class="s">Analytical Likelihood $P(m|s)$</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">legend</span><span class="p">()</span>
    
<span class="k">def</span> <span class="nf">plotMeasurements</span><span class="p">(</span><span class="n">sigma</span><span class="p">,</span> <span class="n">S</span><span class="p">):</span>
    <span class="n">m</span> <span class="o">=</span> <span class="nf">unimodalMeasurements</span><span class="p">(</span><span class="n">sigma</span><span class="p">,</span> <span class="n">S</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">hist</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">density</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">Measurements Histogram</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Measurement $m$</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Density</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sh">'</span><span class="s">Unimodal Measurements Histogram</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">legend</span><span class="p">()</span>      

</code></pre></div></div>

<p><img src="/assets/images/modelsOfbimodal/image 1.png" alt="image.png" /></p>

<p><img src="/assets/images/modelsOfbimodal/image 2.png" alt="image.png" /></p>

<hr />

<h1 id="2-bimodal">2 Bimodal</h1>

<pre><code class="language-mermaid">graph TD
  A(C) --&gt; B1(C=1)
  A --&gt; b2(C=2)
  B1--&gt;b11(S)
  b11--&gt;b111(m_a)
  b11--&gt;b112(m_v)
  b2--&gt;b21(S_a)
  b2--&gt;b22(S_v)
  b21--&gt;b211(m_a)
  b22--&gt;b212(m_v)
  
  
</code></pre>

<hr />

<h2 id="21-fusion-c1">2.1 Fusion (C=1)</h2>

<h3 id="211-fusion-of-one-interval"><strong>2.1.1 Fusion of one interval</strong></h3>

\[\hat{S}_{av,a}=\hat{S}_{av,v}= \frac{\sigma_{av,a}^{-2} m_a+\sigma_{av,v}^{-2} m_v}{\sigma_{av,a}^{-2} + \sigma_{av,v}^{-2}}\\ 
= w_aS_a+w_vS_v\]

\[J_a=\frac{1}{\sigma_{av,a}^{2}} \\
J_v=\frac{1}{\sigma_{av,v}^{2}}\\
\sigma_{av}^2=\frac{1}{J_1+J_2}\]

\[p(S|m_a,m_v)\sim p(S)p(m_a|S)p(m_v|S)\\\]

\[p(S|m_a,m_v)\sim N(\hat S_{av},\sigma_{av}^2)\\\]

\[p(S|m_a,m_v)= \frac{1}{\sqrt{2\pi} \sigma_{av}}\exp(-\frac{(S-\hat S_{av})^2}{2\sigma_{av}^2})\]

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">fusionAV</span><span class="p">(</span><span class="n">sigmaAV_A</span><span class="p">,</span><span class="n">sigmaAV_V</span><span class="p">,</span> <span class="n">S_a</span><span class="p">,</span> <span class="n">visualConflict</span><span class="p">):</span>
    <span class="n">m_a</span><span class="o">=</span><span class="nf">unimodalMeasurements</span><span class="p">(</span><span class="n">sigmaAV_A</span><span class="p">,</span> <span class="n">S_a</span><span class="p">)</span>
    <span class="n">S_v</span><span class="o">=</span><span class="n">S_a</span><span class="o">+</span><span class="n">visualConflict</span>
  <span class="n">m_v</span> <span class="o">=</span> <span class="nf">unimodalMeasurements</span><span class="p">(</span><span class="n">sigmaAV_V</span><span class="p">,</span><span class="n">S_v</span> <span class="p">)</span>  <span class="c1"># visual measurement
</span>  <span class="c1"># compute the precisons inverse of variances
</span>  <span class="n">J_AV_A</span><span class="o">=</span> <span class="n">sigmaAV_A</span><span class="o">**-</span><span class="mi">2</span> <span class="c1"># auditory precision
</span>  <span class="n">J_AV_V</span><span class="o">=</span><span class="n">sigmaAV_V</span><span class="o">**-</span><span class="mi">2</span> <span class="c1"># visual precision
</span>  <span class="c1"># compute the fused estimate using reliability weighted averaging
</span>  <span class="n">hat_S_AV</span><span class="o">=</span> <span class="p">(</span><span class="n">J_AV_A</span><span class="o">*</span><span class="n">m_a</span><span class="o">+</span><span class="n">J_AV_V</span><span class="o">*</span><span class="n">m_v</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="n">J_AV_V</span><span class="o">+</span><span class="n">J_AV_A</span><span class="p">)</span>
    <span class="n">mu_Shat</span> <span class="o">=</span> <span class="n">w_a</span> <span class="o">*</span> <span class="n">S_a</span> <span class="o">+</span> <span class="n">w_v</span> <span class="o">*</span> <span class="n">S_v</span>  <span class="c1"># fused mean
</span>  <span class="n">sigma_S_AV_hat</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="n">J_a</span> <span class="o">+</span> <span class="n">J_v</span><span class="p">))</span>  <span class="c1"># fused standard deviation
</span>
  <span class="k">return</span> <span class="n">hat_S_AV</span> <span class="p">,</span> <span class="n">sigma_S_AV_hat</span> <span class="c1"># belief about fused stimulus value
</span>
</code></pre></div></div>

<p><img src="/assets/images/modelsOfbimodal/image 3.png" alt="image.png" /></p>

<hr />

<h3 id="212-fusion-of-2-ifc-duration-difference">2.1.2 Fusion of 2-IFC Duration Difference</h3>

<p>$\Delta_{t-s}$ is the duration difference between t (test interval) and s (standard interval)</p>

<p>$m_{a,t}$ = measurement for auditory <strong>test</strong> duration.</p>

<p>$m_{a,t}$ = measurement for auditory <strong>standard</strong> duration.</p>

<p>$c$ = conflict duration incorporated to the <strong>visual standard stimulus.</strong></p>

\[\Delta_{t-s}=w_a({m_{a,t}} -m_{a,s})+ w_v ({m_{v,t}} -m_{v,s})\\=w_a\Delta S_a +w_v \Delta S_v\]

\[m_{a,t} - m_{a,s} \sim N(\Delta s_a, 2\sigma^2_a)\\

m_{v,t} - m_{v,s} \sim N(\Delta s_v, 2\sigma^2_v)\]

<p>The difference between two interval within single trial:</p>

\[\Delta_{t-s} = w_a(m_{a,t} - m_{a,s}) + w_v(m_{v,t} - (m_{v,s}))\\ \sim N(w_a\Delta s_a + w_v\Delta s_v, 2\sigma^2_{av})\]

\[\Delta_{t-s} \sim N(\hat S_t - \hat S_s,2\sigma_{av}^2)\]

<hr />

<h3 id="expected-value-of-duration-difference">Expected value of duration difference</h3>

<p><strong>Test Interval:</strong></p>

\[E[m_{v,t}]=E[m_{a,t}]=S_{v,t}=S_{a,t}\]

<p><strong>Standard interval:</strong></p>

\[E[m_{a,s}]=S_{v,s}=S_{a,s}+c\]

<hr />

<p>Duration difference:</p>

\[E[\Delta_{t-s}] = w_a(s_{a,t} - s_{a,s}) + w_v(s_{v,t} - s_{v,s})\]

<p>substituting:</p>

\[S_{v,s}=S_{a,s}+c\]

\[\begin{aligned}
E[\Delta_{t-s}] &amp;= w_a(s_{a,t} - s_{a,s}) + w_v[s_{a,t} - (s_{a,s} + c)] \\
&amp;= w_a(s_{a,t} - s_{a,s}) + w_v(s_{a,t} - s_{a,s} - c) \\
&amp;= (w_a + w_v)(s_{a,t} - s_{a,s}) - w_v c \\
&amp;= (s_{a,t} - s_{a,s}) - w_v c
\end{aligned}\]

<p>Notice that sum of weights equal to 1 as we assume fusion.</p>

<p><strong>Final predict:</strong></p>

\[\Delta_{t-s}=N((S_{a,t}-S_{a,s})-w_vc,2\sigma_{av}^2)\]

<p><strong>$w_vc$ is predicted bias:</strong></p>

<ul>
  <li>if c&gt;0 standard visual is longer), the standard is perceived as longer, so test needs to be even longer to be matched.</li>
  <li>The PSE shifts by $w_vc$</li>
</ul>

<p><strong>Decision Rule:</strong></p>

\[P(\text{"test longer"}) = \Phi\left(\frac{(S_{a,t} - S_{a,s}) - w_v c}{\sqrt{2}\sigma_{av}}\right)\]

<hr />

<h2 id="22-causal-inference-of-2-ifc-duration-difference--c1--c2">2.2 Causal inference of 2-IFC Duration Difference ( C=1 , C=2)</h2>

<h3 id="221-no-common-cause-c2">2.2.1 No common cause (C=2)</h3>

<p>In the case of no common cause, the observer infers that the auditory and visual durations are independent, so that the posterior estimate of different modalities are independent as well.</p>

\[\hat S_{av,a}= m_a, \hat S_{av,v}= m_v, \\
\sigma_{av,a}^2=\sigma_a^2, \sigma_{av,v}^2=\sigma_v^2,\]

<p>We assume that common cause inference is not a binary decision, but rather a continuous variable that can take any value between 0 and 1. The observer can then use this variable to weight the auditory and visual durations in their final estimate. The final estimate is given by:</p>

\[\hat S_{av,a}= \hat S_{av,a} \cdot P(C=1|m_a, m_v) + \hat S_{av,a} \cdot (1 - P(C=1|m_a, m_v))\]

<table>
  <tbody>
    <tr>
      <td>Where $P(C=1</td>
      <td>S_a, S_v)$ is the posterior probability of the common cause given the auditory and visual durations. Observer has measurements:</td>
    </tr>
  </tbody>
</table>

\[\text{Auditory measurement}= m_a\\
\text{Visual measurement}= m_v\\\]

<p>Each is noisy sample:</p>

\[m_a \sim N(S_a, \sigma_{av,a}^2)\\
m_v\sim N(S_v, \sigma_{av,v}^2)\\\]

<p>Here, measurement noise $\sigma_{av,a}$ and $\sigma_{av,v}$ is fit directly from AV bimodal experiment data; we do not assume they are identical to unimodal noise( $\sigma_{av,a} \ne \sigma_a$) as the variance should depend on the context.</p>

<p>This model allows the observer to flexibly integrate the auditory and visual durations based on their prior beliefs about the common cause, leading to more accurate estimates of the durations.</p>

<p>Similarly for the visual duration estimate would be:</p>

\[\hat S_{av,v}= \hat S_{av,v} \cdot P(C=1|m_a, m_v) + \hat S_{av,v} \cdot (1 - P(C=1|m_a, m_v))\]

<p>At this point to solve the model we need to obtain the probability of common source.</p>

\[P(C|m_a,m_v)=\frac{P(m_a,m_v|C)P(C)}{P(m_a,m_v)}\]

<p>and in this case  $p(c=1|m_a,m_v)+p(c=2|m_a,m_v)=1$
When we expand the the common source equation for $C=1$  posterior would be:</p>

<p><strong>Final percept:</strong></p>

\[P(C=1|m_a,m_v)=\frac{p(m_a,m_v|C=1)\cdot p(C=1)}{p(m_a,m_v|C=1)p(C=1)+p(m_a,m_v|C=2)(1-p(c=1))}\]

\[\text{Final auditory estimate}=P(C=1|m_a, m_v)\cdot Fused+ (1-P(C=1|m_a, m_v))\cdot\text{Auditory Only}\]

<p>Simply the decision would be:</p>

\[P(\text{“test longer”}) = \Phi\left(\frac{\hat{S}_{\text{final},t} - \hat{S}_{\text{final},s}}{\sqrt{2}\,\sigma_{\text{decision}}}\right)\]

<table>
  <tbody>
    <tr>
      <td>And the posterior probability for not a common source is: $1-P(C=1</td>
      <td>m_a,m_v)$</td>
    </tr>
  </tbody>
</table>

<p>Now the problem becomes how to estimate the likelihood of the common source given the auditory and visual measurements.</p>

<p>The likelihood of the common source can be estimated using a Gaussian distribution, assuming that the auditory and visual measurements are independent given the common cause. The likelihood can be expressed as:</p>

\[p(m_a,m_v|C=1)= \int p(m_a,m_v|s_{a,v}) p(s_{a,v}) d_{s_{a,v}}\\

= \int p(m_a|s_{a,v})p(m_v|s_{a,v}) p(s_{a,v}) d_{s_{a,v}}\\\]

<h3 id="likelihood-of-the-common-cause-c1"><strong>Likelihood of the common cause (C=1):</strong></h3>

<p><strong>Compute:</strong></p>

\[P(m_a,m_v|C=1)\]

\[P(m_a, m_v | C=1) =\frac{1}{2\pi\sqrt{\sigma_{av,a}^2 \sigma_{av,v}^2+ \sigma_{av,a}^2 \sigma_p^2+ \sigma_{av,v}^2 \sigma_p^2}}\times\ \exp \left(- \frac{1}{2}\frac{(m_a - m_v)^2 \sigma_p^2+ (m_a - \mu_p)^2 \sigma_{av,v}^2+ (m_v - \mu_p)^2 \sigma_{av,a}^2}{\sigma_{av,a}^2\sigma_{av,v}^2 + \sigma_{av,a}^2\sigma_p^2 + \sigma_{av,v}^2\sigma_p^2}\right)\]

\[P(m_a, m_v \mid C = 1) = \frac{1}{\sqrt{2\pi(\sigma^2_{a} + \sigma^2_{v})}} \exp\left(-\frac{(m_a - m_v)^2}{2(\sigma^2_{a} + \sigma^2_{v})}\right)\]

<h3 id="derivation-of-final-likelihood-formula">Derivation of final likelihood formula</h3>

<aside>
💡

**Assumptions:**

**Prior**  duration:

$$
s \sim N(\mu_p, \sigma_p^2)
$$

**Likelihoods (measurement probablities):**

$$
m_a \sim N(s,\sigma_a^2)\\
m_v \sim N(s,\sigma_v^2)
$$

These conditional independencies combined as

We need to **marginalize over s**

$$
p(m_a,m_v|C=1)= \int p(m_a|s)p(m_v|s)p(s)ds
$$

</aside>

<aside>
💡

### **Multiply three Gaussians and integrate**

Then the joint marginal $p(m_a,m_v)$ is:

$$
p(m_a,m_v)=∫N(m_a;s,σ_x^2)⋅N(m_v;s,σ_y^2)⋅N(s;μ,σ^2)ds
$$

the product of $p(m_a|s)$ $p(m_v|s)$ is:

$$
\propto \exp \left( -\frac{(m_a - s)^2}{2\sigma_a^2} - \frac{(m_v - s)^2}{2\sigma_v^2} \right) = \exp \left( -\frac{1}{2} \left[ \frac{(s - m_a)^2}{\sigma_a^2} + \frac{(s - m_v)^2}{\sigma_v^2} \right] \right)
$$

- Adding the prior term:

$$
p(s) = \exp \left( -\frac{(s - \mu_p)^2}{2\sigma_p^2} \right)
$$

**So the total integrand becomes:**

$$
\exp \left( -\frac{1}{2} \left[ \frac{(s - m_a)^2}{\sigma_a^2} + \frac{(s - m_v)^2}{\sigma_v^2} + \frac{(s - \mu_p)^2}{\sigma_p^2} \right] \right)
$$

</aside>

<p><img src="/assets/images/modelsOfbimodal//image 4.png" alt="image.png" /></p>

<hr />

<hr />

<h3 id="detailed-derivation-of-integrand">Detailed derivation of integrand:</h3>

<aside>
💡

$$
\exp \left( -\frac{1}{2} \left[ \frac{(s - m_a)^2}{\sigma_a^2} + \frac{(s - m_v)^2}{\sigma_v^2} + \frac{(s - \mu_p)^2}{\sigma_p^2} \right] \right)
$$

$$
=\frac{1}{2\pi^{3/2}}\cdot exp[-\frac{m_a^2}{2\sigma_a^2}-\frac{-m_v^2}{2\sigma_v^2}-\frac{-\mu_p^2}{2\sigma_p^2}]\int
$$

</aside>

<p>Combine terms by <strong>s</strong></p>

\[p(m_1, m_2 \mid C = 1) =\frac{1}{(2\pi)^{3/2} \sigma_a \sigma_v \sigma_p} \exp\left( - \frac{m_a^2}{2\sigma_a^2} - \frac{m_v^2}{2\sigma_v^2} - \frac{\mu_p^2}{2\sigma_p^2}\right)\int \exp\left( -\frac{A s^2 - 2Bs}{2} \right) ds\]

<p>Where:</p>

\[A = \frac{1}{\sigma_a^2} + \frac{1}{\sigma_v^2} + \frac{1}{\sigma_p^2}, \quad
B = \frac{m_a}{\sigma_a^2} + \frac{m_v}{\sigma_v^2} + \frac{\mu_p}{\sigma_p^2}\]

<p>Here we try to complete the square</p>

<p>using standard gaussian integral</p>

\[\int \exp\left( -\frac{A}{2} \left(s - \frac{B}{A}\right)^2 \right) ds= \sqrt{\frac{2\pi}{A}}\]

<p>So final expression becomes:</p>

\[\int \exp\left( -\frac{A}{2} \left(s - \frac{B}{A}\right)^2 \right) ds= \sqrt{\frac{2\pi}{A}}\]

\[P(m_a, m_v | C=1) =\frac{1}{2\pi\sqrt{\sigma_{av,a}^2 \sigma_{av,v}^2+ \sigma_{av,a}^2 \sigma_p^2+ \sigma_{av,v}^2 \sigma_p^2}}\times\ \exp \left(- \frac{1}{2}\frac{(m_a - m_v)^2 \sigma_p^2+ (m_a - \mu_p)^2 \sigma_{av,v}^2+ (m_v - \mu_p)^2 \sigma_{av,a}^2}{\sigma_{av,a}^2\sigma_{av,v}^2 + \sigma_{av,a}^2\sigma_p^2 + \sigma_{av,v}^2\sigma_p^2}\right)\]

<p>But in this experiment as we are using interleaved 2-IFC AV duration discrimination task we can ignore the prior in the model $\sigma_p^2\sim\infty$. Here are the reasons for why we can assume a flat prior for the dscrimination:</p>

<ul>
  <li>We are using interleaved 2-AFC task which the orrder is mixed.</li>
  <li>In a single trial both the Standard and Test stimuli have the same properties, in other words noise</li>
</ul>

<p><strong>This simplifies the likelihood of common-cause to:</strong></p>

\[P(m_a, m_v \mid C = 1) = \frac{1}{\sqrt{2\pi(\sigma^2_{a} + \sigma^2_{v})}} \exp\left(-\frac{(m_a - m_v)^2}{2(\sigma^2_{a} + \sigma^2_{v})}\right)\]

<aside>
💡

**Derivation from formulate with prior:**

$$
P(m_a, m_v | C=1) =\frac{1}{2\pi\sqrt{\sigma_{av,a}^2 \sigma_{av,v}^2+ \sigma_{av,a}^2 \sigma_p^2+ \sigma_{av,v}^2 \sigma_p^2}}\times\ \exp \left(- \frac{1}{2}\frac{(m_a - m_v)^2 \sigma_p^2+ (m_a - \mu_p)^2 \sigma_{av,v}^2+ (m_v - \mu_p)^2 \sigma_{av,a}^2}{\sigma_{av,a}^2\sigma_{av,v}^2 + \sigma_{av,a}^2\sigma_p^2 + \sigma_{av,v}^2\sigma_p^2}\right)
$$

In this equation lets assume $\sigma_p^2-&gt;\infty$
 1. Denominator the following term becomes:

$$
\sigma_{av,a}^2\sigma_{av,v}^2 + \sigma_{av,a}^2\sigma_p^2 + \sigma_{av,v}^2\sigma_p^2 = \sigma_p^2(\sigma_{av,a}^2+\sigma_{av,v}^2)+\sigma_{av,a}^2\sigma_{av,v}^2\\  
\sim \sigma_p^2(\sigma_{av,a}^2+\sigma_{av,v}^2)
$$

we ignore the $\sigma_a^2\sigma_v^2$ part as it wouldnt be comparable

1. Numerator in
    
    Let’s isolate the dominant term when:
    
    $$
     𝜎_p^2→ ∞
    $$
    
    Then 
    
    Only the **first term** grows without bound:
    
    $$
    (m_a - m_v)^2 \sigma_p^2
    $$
    
    So the **dominant contribution** to the exponent becomes:
    
    $$
    \exp \left( -\frac{1}{2} \cdot \frac{(m_a - m_v)^2 \sigma_p^2}{\sigma_p^2(\sigma_a^2 + \sigma_v^2)} \right) = \exp \left( -\frac{(m_a - m_v)^2}{2(\sigma_a^2 + \sigma_v^2)} \right)
    $$
    
2. When we combine all:

$$
P(m_a, m_v | C=1) \approx \frac{1}{2\pi\sigma_p\sqrt{\sigma_a^2 + \sigma_v^2}} \cdot \exp \left( -\frac{(m_a - m_v)^2}{2(\sigma_a^2 + \sigma_v^2)} \right)
$$

 4. Then we renormalize:

In general we can say that

$$
\int exp[-\frac{1}{2}\frac{x^2}{A^2}]=\sqrt{2\pi} A
$$

Here sicnce below equation integrates to unity.  This amounts to **dividing by its own integral**:

and 

$$
x=m_a-m_v\\
A=\sigma_{av,a}^2+\sigma_{av,v}^2\\

$$

$$
\int_{-\infty}^{\infty} \exp\left[-\frac{(m_a - m_v)^2}{2(\sigma_a^2 + \sigma_v^2)}\right] d(m_a - m_v) = \sqrt{2\pi(\sigma_a^2 + \sigma_v^2)}.
$$

1. Hence the correctly normalised, “flat–prior” likelihood is
    
    $$
    P(m_a, m_v \mid C = 1) = \frac{1}{\sqrt{2\pi(\sigma^2_{a} + \sigma^2_{v})}} \exp\left(-\frac{(m_a - m_v)^2}{2(\sigma^2_{a} + \sigma^2_{v})}\right)
    $$
    

</aside>

<p><strong>So that integration</strong> was used twice:</p>

<ul>
  <li>once to marginalise over sss,</li>
  <li>once more (conceptually) to compute the normalising constant of the Δ\DeltaΔ-Gaussian.</li>
</ul>

<h3 id="likelihood-of-independent-sources-c2"><strong>Likelihood of independent sources (C=2):</strong></h3>

\[P(m_a, m_v | C=2,s_a,s_v) = P(m_a) \cdot P(m_v)\]

\[= \frac{1}{2\pi \sigma_{av,a} \sigma_{av,v}}\exp\left(    -\frac{(m_a - s_a)^2}{2\sigma_{av,a}^2}    -\frac{(m_v - s_v)^2}{2\sigma_{av,v}^2}\right)\]

<h2 id="decision"><strong>Decision:</strong></h2>

<p>Finally model should compare the estimated duration for both ‘test’ and ‘standard’ intervals decision should be computed as:</p>

<p>decision should be computed as:</p>

\[⁍\]

\[P(\text{"test longer"}) = \Phi\left(\frac{D}{\sqrt{2}\sigma_{CI}}\right)\]

<p>$\hat S_{CI,t}$ The final internal estimate for the duration of the test interval and $\hat S_{CI,s}$ is the final internal estimate for the standard interval after causal inference.</p>

<p>$\sigma_{CI}$ is the <strong>effective sensory noise</strong> (standard deviation) associated with the internal estimate in the causal inference model.</p>

<p><img src="/assets/images/modelsOfbimodal/image 5.png" alt="image.png" /></p>]]></content><author><name>Omer Yildiran</name></author><summary type="html"><![CDATA[Model Coding:]]></summary></entry></feed>