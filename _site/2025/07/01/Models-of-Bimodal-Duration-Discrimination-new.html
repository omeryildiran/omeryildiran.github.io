<!DOCTYPE html> <html lang="en-US"> <head> <meta charset="UTF-8"> <meta http-equiv="X-UA-Compatible" content="IE=Edge"> <link rel="stylesheet" href="/assets/css/just-the-docs-default.css"> <link rel="stylesheet" href="/assets/css/just-the-docs-head-nav.css" id="jtd-head-nav-stylesheet"> <style id="jtd-nav-activation"> .site-nav ul li a { background-image: none; } </style> <script src="/assets/js/vendor/lunr.min.js"></script> <script src="/assets/js/just-the-docs.js"></script> <meta name="viewport" content="width=device-width, initial-scale=1"> <!-- Begin Jekyll SEO tag v2.8.0 --> <title>Models of Bimodal Duration Estimation | Omer Yildiran</title> <meta name="generator" content="Jekyll v4.4.1" /> <meta property="og:title" content="Models of Bimodal Duration Estimation" /> <meta name="author" content="Omer Yildiran" /> <meta property="og:locale" content="en_US" /> <meta name="description" content="Model Coding:" /> <meta property="og:description" content="Model Coding:" /> <link rel="canonical" href="http://localhost:4000/2025/07/01/Models-of-Bimodal-Duration-Discrimination-new.html" /> <meta property="og:url" content="http://localhost:4000/2025/07/01/Models-of-Bimodal-Duration-Discrimination-new.html" /> <meta property="og:site_name" content="Omer Yildiran" /> <meta property="og:type" content="article" /> <meta property="article:published_time" content="2025-07-01T00:00:00+02:00" /> <meta name="twitter:card" content="summary" /> <meta property="twitter:title" content="Models of Bimodal Duration Estimation" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Omer Yildiran"},"dateModified":"2025-07-01T00:00:00+02:00","datePublished":"2025-07-01T00:00:00+02:00","description":"Model Coding:","headline":"Models of Bimodal Duration Estimation","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/2025/07/01/Models-of-Bimodal-Duration-Discrimination-new.html"},"url":"http://localhost:4000/2025/07/01/Models-of-Bimodal-Duration-Discrimination-new.html"}</script> <!-- End Jekyll SEO tag --> <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"> </script> </head> <body> <a class="skip-to-main" href="#main-content">Skip to main content</a> <svg xmlns="http://www.w3.org/2000/svg" class="d-none"> <symbol id="svg-link" viewBox="0 0 24 24"> <title>Link</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-link"> <path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path> </svg> </symbol> <symbol id="svg-menu" viewBox="0 0 24 24"> <title>Menu</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-menu"> <line x1="3" y1="12" x2="21" y2="12"></line><line x1="3" y1="6" x2="21" y2="6"></line><line x1="3" y1="18" x2="21" y2="18"></line> </svg> </symbol> <symbol id="svg-arrow-right" viewBox="0 0 24 24"> <title>Expand</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-chevron-right"> <polyline points="9 18 15 12 9 6"></polyline> </svg> </symbol> <!-- Feather. MIT License: https://github.com/feathericons/feather/blob/master/LICENSE --> <symbol id="svg-external-link" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-external-link"> <title id="svg-external-link-title">(external link)</title> <path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path><polyline points="15 3 21 3 21 9"></polyline><line x1="10" y1="14" x2="21" y2="3"></line> </symbol> <symbol id="svg-doc" viewBox="0 0 24 24"> <title>Document</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-file"> <path d="M13 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V9z"></path><polyline points="13 2 13 9 20 9"></polyline> </svg> </symbol> <symbol id="svg-search" viewBox="0 0 24 24"> <title>Search</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-search"> <circle cx="11" cy="11" r="8"></circle><line x1="21" y1="21" x2="16.65" y2="16.65"></line> </svg> </symbol> <!-- Bootstrap Icons. MIT License: https://github.com/twbs/icons/blob/main/LICENSE.md --> <symbol id="svg-copy" viewBox="0 0 16 16"> <title>Copy</title> <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-clipboard" viewBox="0 0 16 16"> <path d="M4 1.5H3a2 2 0 0 0-2 2V14a2 2 0 0 0 2 2h10a2 2 0 0 0 2-2V3.5a2 2 0 0 0-2-2h-1v1h1a1 1 0 0 1 1 1V14a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V3.5a1 1 0 0 1 1-1h1v-1z"/> <path d="M9.5 1a.5.5 0 0 1 .5.5v1a.5.5 0 0 1-.5.5h-3a.5.5 0 0 1-.5-.5v-1a.5.5 0 0 1 .5-.5h3zm-3-1A1.5 1.5 0 0 0 5 1.5v1A1.5 1.5 0 0 0 6.5 4h3A1.5 1.5 0 0 0 11 2.5v-1A1.5 1.5 0 0 0 9.5 0h-3z"/> </svg> </symbol> <symbol id="svg-copied" viewBox="0 0 16 16"> <title>Copied</title> <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-clipboard-check-fill" viewBox="0 0 16 16"> <path d="M6.5 0A1.5 1.5 0 0 0 5 1.5v1A1.5 1.5 0 0 0 6.5 4h3A1.5 1.5 0 0 0 11 2.5v-1A1.5 1.5 0 0 0 9.5 0h-3Zm3 1a.5.5 0 0 1 .5.5v1a.5.5 0 0 1-.5.5h-3a.5.5 0 0 1-.5-.5v-1a.5.5 0 0 1 .5-.5h3Z"/> <path d="M4 1.5H3a2 2 0 0 0-2 2V14a2 2 0 0 0 2 2h10a2 2 0 0 0 2-2V3.5a2 2 0 0 0-2-2h-1v1A2.5 2.5 0 0 1 9.5 5h-3A2.5 2.5 0 0 1 4 2.5v-1Zm6.854 7.354-3 3a.5.5 0 0 1-.708 0l-1.5-1.5a.5.5 0 0 1 .708-.708L7.5 10.793l2.646-2.647a.5.5 0 0 1 .708.708Z"/> </svg> </symbol> </svg> <div class="side-bar"> <div class="site-header" role="banner"> <a href="/" class="site-title lh-tight"> Omer Yildiran </a> <button id="menu-button" class="site-button btn-reset" aria-label="Toggle menu" aria-pressed="false"> <svg viewBox="0 0 24 24" class="icon" aria-hidden="true"><use xlink:href="#svg-menu"></use></svg> </button> </div> <nav aria-label="Main" id="site-nav" class="site-nav"> <ul class="nav-list"><li class="nav-list-item"><a href="/blog.html" class="nav-list-link">Posts</a></li><li class="nav-list-item"><a href="/about/" class="nav-list-link">About Me</a></li><li class="nav-list-item"><a href="/projects/" class="nav-list-link">Projects</a></li></ul> </nav> <footer class="site-footer"> This site uses <a href="https://github.com/just-the-docs/just-the-docs">Just the Docs</a>, a documentation theme for Jekyll. </footer> </div> <div class="main" id="top"> <div id="main-header" class="main-header"> <div class="search" role="search"> <div class="search-input-wrap"> <input type="text" id="search-input" class="search-input" tabindex="0" placeholder="Search Omer Yildiran" aria-label="Search Omer Yildiran" autocomplete="off"> <label for="search-input" class="search-label"><svg viewBox="0 0 24 24" class="search-icon"><use xlink:href="#svg-search"></use></svg></label> </div> <div id="search-results" class="search-results"></div> </div> </div> <div class="main-content-wrap"> <div id="main-content" class="main-content"> <main> <h1 id="model-coding"> <a href="#model-coding" class="anchor-heading" aria-labelledby="model-coding"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Model Coding: </h1> <p>Created: June 18, 2025 6:09 PM Tags: article note</p> <h1 id="1--unimodal"> <a href="#1--unimodal" class="anchor-heading" aria-labelledby="1--unimodal"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 1- Unimodal </h1> <h3 id="11-measurement"> <a href="#11-measurement" class="anchor-heading" aria-labelledby="11-measurement"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 1.1 Measurement </h3> <p><img src="/assets/images/modelsOfbimodal/imageHo.png" alt="imageHo" /></p> \[m=N(s,\sigma^2)\] <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># unimodal measurements
</span><span class="k">def</span> <span class="nf">unimodalMeasurements</span><span class="p">(</span><span class="n">sigma</span><span class="p">,</span> <span class="n">S</span><span class="p">):</span>
    <span class="c1"># P(x|s) # generate measurements from a normal distribution
</span>    <span class="n">m</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">normal</span><span class="p">(</span><span class="n">S</span><span class="p">,</span> <span class="n">sigma</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="mi">10000</span><span class="p">)</span>  <span class="c1"># true duration is S seconds
</span>    <span class="k">return</span> <span class="n">m</span>

</code></pre></div></div> <h3 id="12-likelihood"> <a href="#12-likelihood" class="anchor-heading" aria-labelledby="12-likelihood"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> <strong>1.2 Likelihood</strong> </h3> \[p(m|s)=\frac{1}{\sqrt{2\pi} \sigma}\exp(-\frac{(m-s)^2}{2\sigma^2})\] <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">gaussianPDF</span><span class="p">(</span><span class="n">m</span><span class="p">,</span><span class="n">s</span><span class="p">,</span><span class="n">sigma</span><span class="p">):</span>
    <span class="nf">return </span><span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">np</span><span class="p">.</span><span class="n">pi</span><span class="p">)</span><span class="o">*</span><span class="n">sigma</span><span class="p">))</span><span class="o">*</span><span class="n">np</span><span class="p">.</span><span class="nf">exp</span><span class="p">(</span><span class="o">-</span><span class="p">((</span><span class="n">x</span><span class="o">-</span><span class="n">s</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="p">(</span><span class="n">sigma</span><span class="o">**</span><span class="mi">2</span><span class="p">)))</span>

<span class="c1"># likelihood function
</span><span class="k">def</span> <span class="nf">likelihood</span><span class="p">(</span><span class="n">S</span><span class="p">,</span> <span class="n">sigma</span><span class="p">):</span>
    <span class="c1"># P(m|s) # likelihood of measurements given the true duration
</span>    <span class="n">m</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="nf">linspace</span><span class="p">(</span><span class="n">S</span> <span class="o">-</span> <span class="mi">4</span><span class="o">*</span><span class="n">sigma</span><span class="p">,</span> <span class="n">S</span> <span class="o">+</span> <span class="mi">4</span><span class="o">*</span><span class="n">sigma</span><span class="p">,</span> <span class="mi">500</span><span class="p">)</span>
    <span class="n">p_x</span><span class="o">=</span><span class="nf">gaussianPDF</span><span class="p">(</span><span class="n">m</span><span class="p">,</span><span class="n">S</span><span class="p">,</span><span class="n">sigma</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">x</span><span class="p">,</span> <span class="n">p_x</span>

</code></pre></div></div> <p>1.2.1 <strong>Plot Likelihoods analytically</strong></p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">plotLikelihood</span><span class="p">(</span><span class="n">S</span><span class="p">,</span><span class="n">sigma</span><span class="p">):</span>
    <span class="n">x</span><span class="p">,</span> <span class="n">p_x</span> <span class="o">=</span> <span class="nf">likelihood</span><span class="p">(</span><span class="n">S</span><span class="p">,</span> <span class="n">sigma</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">p_x</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">Likelihood Function</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Measurement $m$</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Probability Density</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sh">'</span><span class="s">Analytical Likelihood $P(m|s)$</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">legend</span><span class="p">()</span>
    
<span class="k">def</span> <span class="nf">plotMeasurements</span><span class="p">(</span><span class="n">sigma</span><span class="p">,</span> <span class="n">S</span><span class="p">):</span>
    <span class="n">m</span> <span class="o">=</span> <span class="nf">unimodalMeasurements</span><span class="p">(</span><span class="n">sigma</span><span class="p">,</span> <span class="n">S</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">hist</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">density</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">Measurements Histogram</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Measurement $m$</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Density</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sh">'</span><span class="s">Unimodal Measurements Histogram</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">legend</span><span class="p">()</span>      

</code></pre></div></div> <p><img src="/assets/images/modelsOfbimodal/image 1.png" alt="image.png" /></p> <p><img src="/assets/images/modelsOfbimodal/image 2.png" alt="image.png" /></p><hr /> <h1 id="2-bimodal"> <a href="#2-bimodal" class="anchor-heading" aria-labelledby="2-bimodal"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 2 Bimodal </h1><pre><code class="language-mermaid">graph TD
  A(C) --&gt; B1(C=1)
  A --&gt; b2(C=2)
  B1--&gt;b11(S)
  b11--&gt;b111(m_a)
  b11--&gt;b112(m_v)
  b2--&gt;b21(S_a)
  b2--&gt;b22(S_v)
  b21--&gt;b211(m_a)
  b22--&gt;b212(m_v)
  
  
</code></pre><hr /> <h2 id="21-fusion-c1"> <a href="#21-fusion-c1" class="anchor-heading" aria-labelledby="21-fusion-c1"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 2.1 Fusion (C=1) </h2> <h3 id="211-fusion-of-one-interval"> <a href="#211-fusion-of-one-interval" class="anchor-heading" aria-labelledby="211-fusion-of-one-interval"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> <strong>2.1.1 Fusion of one interval</strong> </h3> \[\hat{S}_{av,a}=\hat{S}_{av,v}= \frac{\sigma_{av,a}^{-2} m_a+\sigma_{av,v}^{-2} m_v}{\sigma_{av,a}^{-2} + \sigma_{av,v}^{-2}}\\ = w_aS_a+w_vS_v\] \[J_a=\frac{1}{\sigma_{av,a}^{2}} \\ J_v=\frac{1}{\sigma_{av,v}^{2}}\\ \sigma_{av}^2=\frac{1}{J_1+J_2}\] \[p(S|m_a,m_v)\sim p(S)p(m_a|S)p(m_v|S)\\\] \[p(S|m_a,m_v)\sim N(\hat S_{av},\sigma_{av}^2)\\\] \[p(S|m_a,m_v)= \frac{1}{\sqrt{2\pi} \sigma_{av}}\exp(-\frac{(S-\hat S_{av})^2}{2\sigma_{av}^2})\] <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">fusionAV</span><span class="p">(</span><span class="n">sigmaAV_A</span><span class="p">,</span><span class="n">sigmaAV_V</span><span class="p">,</span> <span class="n">S_a</span><span class="p">,</span> <span class="n">visualConflict</span><span class="p">):</span>
    <span class="n">m_a</span><span class="o">=</span><span class="nf">unimodalMeasurements</span><span class="p">(</span><span class="n">sigmaAV_A</span><span class="p">,</span> <span class="n">S_a</span><span class="p">)</span>
    <span class="n">S_v</span><span class="o">=</span><span class="n">S_a</span><span class="o">+</span><span class="n">visualConflict</span>
  <span class="n">m_v</span> <span class="o">=</span> <span class="nf">unimodalMeasurements</span><span class="p">(</span><span class="n">sigmaAV_V</span><span class="p">,</span><span class="n">S_v</span> <span class="p">)</span>  <span class="c1"># visual measurement
</span>  <span class="c1"># compute the precisons inverse of variances
</span>  <span class="n">J_AV_A</span><span class="o">=</span> <span class="n">sigmaAV_A</span><span class="o">**-</span><span class="mi">2</span> <span class="c1"># auditory precision
</span>  <span class="n">J_AV_V</span><span class="o">=</span><span class="n">sigmaAV_V</span><span class="o">**-</span><span class="mi">2</span> <span class="c1"># visual precision
</span>  <span class="c1"># compute the fused estimate using reliability weighted averaging
</span>  <span class="n">hat_S_AV</span><span class="o">=</span> <span class="p">(</span><span class="n">J_AV_A</span><span class="o">*</span><span class="n">m_a</span><span class="o">+</span><span class="n">J_AV_V</span><span class="o">*</span><span class="n">m_v</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="n">J_AV_V</span><span class="o">+</span><span class="n">J_AV_A</span><span class="p">)</span>
    <span class="n">mu_Shat</span> <span class="o">=</span> <span class="n">w_a</span> <span class="o">*</span> <span class="n">S_a</span> <span class="o">+</span> <span class="n">w_v</span> <span class="o">*</span> <span class="n">S_v</span>  <span class="c1"># fused mean
</span>  <span class="n">sigma_S_AV_hat</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="n">J_a</span> <span class="o">+</span> <span class="n">J_v</span><span class="p">))</span>  <span class="c1"># fused standard deviation
</span>
  <span class="k">return</span> <span class="n">hat_S_AV</span> <span class="p">,</span> <span class="n">sigma_S_AV_hat</span> <span class="c1"># belief about fused stimulus value
</span>
</code></pre></div></div> <p><img src="/assets/images/modelsOfbimodal/image 3.png" alt="image.png" /></p><hr /> <h3 id="212-fusion-of-2-ifc-duration-difference"> <a href="#212-fusion-of-2-ifc-duration-difference" class="anchor-heading" aria-labelledby="212-fusion-of-2-ifc-duration-difference"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 2.1.2 Fusion of 2-IFC Duration Difference </h3> <p>$\Delta_{t-s}$ is the duration difference between t (test interval) and s (standard interval)</p> <p>$m_{a,t}$ = measurement for auditory <strong>test</strong> duration.</p> <p>$m_{a,t}$ = measurement for auditory <strong>standard</strong> duration.</p> <p>$c$ = conflict duration incorporated to the <strong>visual standard stimulus.</strong></p> \[\Delta_{t-s}=w_a({m_{a,t}} -m_{a,s})+ w_v ({m_{v,t}} -m_{v,s})\\=w_a\Delta S_a +w_v \Delta S_v\] \[m_{a,t} - m_{a,s} \sim N(\Delta s_a, 2\sigma^2_a)\\ m_{v,t} - m_{v,s} \sim N(\Delta s_v, 2\sigma^2_v)\] <p>The difference between two interval within single trial:</p> \[\Delta_{t-s} = w_a(m_{a,t} - m_{a,s}) + w_v(m_{v,t} - (m_{v,s}))\\ \sim N(w_a\Delta s_a + w_v\Delta s_v, 2\sigma^2_{av})\] \[\Delta_{t-s} \sim N(\hat S_t - \hat S_s,2\sigma_{av}^2)\]<hr /> <h3 id="expected-value-of-duration-difference"> <a href="#expected-value-of-duration-difference" class="anchor-heading" aria-labelledby="expected-value-of-duration-difference"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Expected value of duration difference </h3> <p><strong>Test Interval:</strong></p> \[E[m_{v,t}]=E[m_{a,t}]=S_{v,t}=S_{a,t}\] <p><strong>Standard interval:</strong></p> \[E[m_{a,s}]=S_{v,s}=S_{a,s}+c\]<hr /> <p>Duration difference:</p> \[E[\Delta_{t-s}] = w_a(s_{a,t} - s_{a,s}) + w_v(s_{v,t} - s_{v,s})\] <p>substituting:</p> \[S_{v,s}=S_{a,s}+c\] \[\begin{aligned} E[\Delta_{t-s}] &amp;= w_a(s_{a,t} - s_{a,s}) + w_v[s_{a,t} - (s_{a,s} + c)] \\ &amp;= w_a(s_{a,t} - s_{a,s}) + w_v(s_{a,t} - s_{a,s} - c) \\ &amp;= (w_a + w_v)(s_{a,t} - s_{a,s}) - w_v c \\ &amp;= (s_{a,t} - s_{a,s}) - w_v c \end{aligned}\] <p>Notice that sum of weights equal to 1 as we assume fusion.</p> <p><strong>Final predict:</strong></p> \[\Delta_{t-s}=N((S_{a,t}-S_{a,s})-w_vc,2\sigma_{av}^2)\] <p><strong>$w_vc$ is predicted bias:</strong></p> <ul> <li>if c&gt;0 standard visual is longer), the standard is perceived as longer, so test needs to be even longer to be matched.</li> <li>The PSE shifts by $w_vc$</li> </ul> <p><strong>Decision Rule:</strong></p> \[P(\text{"test longer"}) = \Phi\left(\frac{(S_{a,t} - S_{a,s}) - w_v c}{\sqrt{2}\sigma_{av}}\right)\]<hr /> <h2 id="22-causal-inference-of-2-ifc-duration-difference--c1--c2"> <a href="#22-causal-inference-of-2-ifc-duration-difference--c1--c2" class="anchor-heading" aria-labelledby="22-causal-inference-of-2-ifc-duration-difference--c1--c2"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 2.2 Causal inference of 2-IFC Duration Difference ( C=1 , C=2) </h2> <h3 id="221-no-common-cause-c2"> <a href="#221-no-common-cause-c2" class="anchor-heading" aria-labelledby="221-no-common-cause-c2"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 2.2.1 No common cause (C=2) </h3> <p>In the case of no common cause, the observer infers that the auditory and visual durations are independent, so that the posterior estimate of different modalities are independent as well.</p> \[\hat S_{av,a}= m_a, \hat S_{av,v}= m_v, \\ \sigma_{av,a}^2=\sigma_a^2, \sigma_{av,v}^2=\sigma_v^2,\] <p>We assume that common cause inference is not a binary decision, but rather a continuous variable that can take any value between 0 and 1. The observer can then use this variable to weight the auditory and visual durations in their final estimate. The final estimate is given by:</p> \[\hat S_{av,a}= \hat S_{av,a} \cdot P(C=1|m_a, m_v) + \hat S_{av,a} \cdot (1 - P(C=1|m_a, m_v))\] <div class="table-wrapper"><table> <tbody> <tr> <td>Where $P(C=1</td> <td>S_a, S_v)$ is the posterior probability of the common cause given the auditory and visual durations. Observer has measurements:</td> </tr> </tbody> </table></div> \[\text{Auditory measurement}= m_a\\ \text{Visual measurement}= m_v\\\] <p>Each is noisy sample:</p> \[m_a \sim N(S_a, \sigma_{av,a}^2)\\ m_v\sim N(S_v, \sigma_{av,v}^2)\\\] <p>Here, measurement noise $\sigma_{av,a}$ and $\sigma_{av,v}$ is fit directly from AV bimodal experiment data; we do not assume they are identical to unimodal noise( $\sigma_{av,a} \ne \sigma_a$) as the variance should depend on the context.</p> <p>This model allows the observer to flexibly integrate the auditory and visual durations based on their prior beliefs about the common cause, leading to more accurate estimates of the durations.</p> <p>Similarly for the visual duration estimate would be:</p> \[\hat S_{av,v}= \hat S_{av,v} \cdot P(C=1|m_a, m_v) + \hat S_{av,v} \cdot (1 - P(C=1|m_a, m_v))\] <p>At this point to solve the model we need to obtain the probability of common source.</p> \[P(C|m_a,m_v)=\frac{P(m_a,m_v|C)P(C)}{P(m_a,m_v)}\] <p>and in this case $p(c=1|m_a,m_v)+p(c=2|m_a,m_v)=1$ When we expand the the common source equation for $C=1$ posterior would be:</p> <p><strong>Final percept:</strong></p> \[P(C=1|m_a,m_v)=\frac{p(m_a,m_v|C=1)\cdot p(C=1)}{p(m_a,m_v|C=1)p(C=1)+p(m_a,m_v|C=2)(1-p(c=1))}\] \[\text{Final auditory estimate}=P(C=1|m_a, m_v)\cdot Fused+ (1-P(C=1|m_a, m_v))\cdot\text{Auditory Only}\] <p>Simply the decision would be:</p> \[P(\text{“test longer”}) = \Phi\left(\frac{\hat{S}_{\text{final},t} - \hat{S}_{\text{final},s}}{\sqrt{2}\,\sigma_{\text{decision}}}\right)\] <div class="table-wrapper"><table> <tbody> <tr> <td>And the posterior probability for not a common source is: $1-P(C=1</td> <td>m_a,m_v)$</td> </tr> </tbody> </table></div> <p>Now the problem becomes how to estimate the likelihood of the common source given the auditory and visual measurements.</p> <p>The likelihood of the common source can be estimated using a Gaussian distribution, assuming that the auditory and visual measurements are independent given the common cause. The likelihood can be expressed as:</p> \[p(m_a,m_v|C=1)= \int p(m_a,m_v|s_{a,v}) p(s_{a,v}) d_{s_{a,v}}\\ = \int p(m_a|s_{a,v})p(m_v|s_{a,v}) p(s_{a,v}) d_{s_{a,v}}\\\] <h3 id="likelihood-of-the-common-cause-c1"> <a href="#likelihood-of-the-common-cause-c1" class="anchor-heading" aria-labelledby="likelihood-of-the-common-cause-c1"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> <strong>Likelihood of the common cause (C=1):</strong> </h3> <p><strong>Compute:</strong></p> \[P(m_a,m_v|C=1)\] \[P(m_a, m_v | C=1) =\frac{1}{2\pi\sqrt{\sigma_{av,a}^2 \sigma_{av,v}^2+ \sigma_{av,a}^2 \sigma_p^2+ \sigma_{av,v}^2 \sigma_p^2}}\times\ \exp \left(- \frac{1}{2}\frac{(m_a - m_v)^2 \sigma_p^2+ (m_a - \mu_p)^2 \sigma_{av,v}^2+ (m_v - \mu_p)^2 \sigma_{av,a}^2}{\sigma_{av,a}^2\sigma_{av,v}^2 + \sigma_{av,a}^2\sigma_p^2 + \sigma_{av,v}^2\sigma_p^2}\right)\] \[P(m_a, m_v \mid C = 1) = \frac{1}{\sqrt{2\pi(\sigma^2_{a} + \sigma^2_{v})}} \exp\left(-\frac{(m_a - m_v)^2}{2(\sigma^2_{a} + \sigma^2_{v})}\right)\] <h3 id="derivation-of-final-likelihood-formula"> <a href="#derivation-of-final-likelihood-formula" class="anchor-heading" aria-labelledby="derivation-of-final-likelihood-formula"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Derivation of final likelihood formula </h3> <aside> 💡 **Assumptions:** **Prior** duration: $$ s \sim N(\mu_p, \sigma_p^2) $$ **Likelihoods (measurement probablities):** $$ m_a \sim N(s,\sigma_a^2)\\ m_v \sim N(s,\sigma_v^2) $$ These conditional independencies combined as We need to **marginalize over s** $$ p(m_a,m_v|C=1)= \int p(m_a|s)p(m_v|s)p(s)ds $$ </aside> <aside> 💡 ### **Multiply three Gaussians and integrate** Then the joint marginal $p(m_a,m_v)$ is: $$ p(m_a,m_v)=∫N(m_a;s,σ_x^2)⋅N(m_v;s,σ_y^2)⋅N(s;μ,σ^2)ds $$ the product of $p(m_a|s)$ $p(m_v|s)$ is: $$ \propto \exp \left( -\frac{(m_a - s)^2}{2\sigma_a^2} - \frac{(m_v - s)^2}{2\sigma_v^2} \right) = \exp \left( -\frac{1}{2} \left[ \frac{(s - m_a)^2}{\sigma_a^2} + \frac{(s - m_v)^2}{\sigma_v^2} \right] \right) $$ - Adding the prior term: $$ p(s) = \exp \left( -\frac{(s - \mu_p)^2}{2\sigma_p^2} \right) $$ **So the total integrand becomes:** $$ \exp \left( -\frac{1}{2} \left[ \frac{(s - m_a)^2}{\sigma_a^2} + \frac{(s - m_v)^2}{\sigma_v^2} + \frac{(s - \mu_p)^2}{\sigma_p^2} \right] \right) $$ </aside> <p><img src="/assets/images/modelsOfbimodal//image 4.png" alt="image.png" /></p><hr /><hr /> <h3 id="detailed-derivation-of-integrand"> <a href="#detailed-derivation-of-integrand" class="anchor-heading" aria-labelledby="detailed-derivation-of-integrand"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Detailed derivation of integrand: </h3> <aside> 💡 $$ \exp \left( -\frac{1}{2} \left[ \frac{(s - m_a)^2}{\sigma_a^2} + \frac{(s - m_v)^2}{\sigma_v^2} + \frac{(s - \mu_p)^2}{\sigma_p^2} \right] \right) $$ $$ =\frac{1}{2\pi^{3/2}}\cdot exp[-\frac{m_a^2}{2\sigma_a^2}-\frac{-m_v^2}{2\sigma_v^2}-\frac{-\mu_p^2}{2\sigma_p^2}]\int $$ </aside> <p>Combine terms by <strong>s</strong></p> \[p(m_1, m_2 \mid C = 1) =\frac{1}{(2\pi)^{3/2} \sigma_a \sigma_v \sigma_p} \exp\left( - \frac{m_a^2}{2\sigma_a^2} - \frac{m_v^2}{2\sigma_v^2} - \frac{\mu_p^2}{2\sigma_p^2}\right)\int \exp\left( -\frac{A s^2 - 2Bs}{2} \right) ds\] <p>Where:</p> \[A = \frac{1}{\sigma_a^2} + \frac{1}{\sigma_v^2} + \frac{1}{\sigma_p^2}, \quad B = \frac{m_a}{\sigma_a^2} + \frac{m_v}{\sigma_v^2} + \frac{\mu_p}{\sigma_p^2}\] <p>Here we try to complete the square</p> <p>using standard gaussian integral</p> \[\int \exp\left( -\frac{A}{2} \left(s - \frac{B}{A}\right)^2 \right) ds= \sqrt{\frac{2\pi}{A}}\] <p>So final expression becomes:</p> \[\int \exp\left( -\frac{A}{2} \left(s - \frac{B}{A}\right)^2 \right) ds= \sqrt{\frac{2\pi}{A}}\] \[P(m_a, m_v | C=1) =\frac{1}{2\pi\sqrt{\sigma_{av,a}^2 \sigma_{av,v}^2+ \sigma_{av,a}^2 \sigma_p^2+ \sigma_{av,v}^2 \sigma_p^2}}\times\ \exp \left(- \frac{1}{2}\frac{(m_a - m_v)^2 \sigma_p^2+ (m_a - \mu_p)^2 \sigma_{av,v}^2+ (m_v - \mu_p)^2 \sigma_{av,a}^2}{\sigma_{av,a}^2\sigma_{av,v}^2 + \sigma_{av,a}^2\sigma_p^2 + \sigma_{av,v}^2\sigma_p^2}\right)\] <p>But in this experiment as we are using interleaved 2-IFC AV duration discrimination task we can ignore the prior in the model $\sigma_p^2\sim\infty$. Here are the reasons for why we can assume a flat prior for the dscrimination:</p> <ul> <li>We are using interleaved 2-AFC task which the orrder is mixed.</li> <li>In a single trial both the Standard and Test stimuli have the same properties, in other words noise</li> </ul> <p><strong>This simplifies the likelihood of common-cause to:</strong></p> \[P(m_a, m_v \mid C = 1) = \frac{1}{\sqrt{2\pi(\sigma^2_{a} + \sigma^2_{v})}} \exp\left(-\frac{(m_a - m_v)^2}{2(\sigma^2_{a} + \sigma^2_{v})}\right)\] <aside> 💡 **Derivation from formulate with prior:** $$ P(m_a, m_v | C=1) =\frac{1}{2\pi\sqrt{\sigma_{av,a}^2 \sigma_{av,v}^2+ \sigma_{av,a}^2 \sigma_p^2+ \sigma_{av,v}^2 \sigma_p^2}}\times\ \exp \left(- \frac{1}{2}\frac{(m_a - m_v)^2 \sigma_p^2+ (m_a - \mu_p)^2 \sigma_{av,v}^2+ (m_v - \mu_p)^2 \sigma_{av,a}^2}{\sigma_{av,a}^2\sigma_{av,v}^2 + \sigma_{av,a}^2\sigma_p^2 + \sigma_{av,v}^2\sigma_p^2}\right) $$ In this equation lets assume $\sigma_p^2-&gt;\infty$ 1. Denominator the following term becomes: $$ \sigma_{av,a}^2\sigma_{av,v}^2 + \sigma_{av,a}^2\sigma_p^2 + \sigma_{av,v}^2\sigma_p^2 = \sigma_p^2(\sigma_{av,a}^2+\sigma_{av,v}^2)+\sigma_{av,a}^2\sigma_{av,v}^2\\ \sim \sigma_p^2(\sigma_{av,a}^2+\sigma_{av,v}^2) $$ we ignore the $\sigma_a^2\sigma_v^2$ part as it wouldnt be comparable 1. Numerator in Let’s isolate the dominant term when: $$ 𝜎_p^2→ ∞ $$ Then Only the **first term** grows without bound: $$ (m_a - m_v)^2 \sigma_p^2 $$ So the **dominant contribution** to the exponent becomes: $$ \exp \left( -\frac{1}{2} \cdot \frac{(m_a - m_v)^2 \sigma_p^2}{\sigma_p^2(\sigma_a^2 + \sigma_v^2)} \right) = \exp \left( -\frac{(m_a - m_v)^2}{2(\sigma_a^2 + \sigma_v^2)} \right) $$ 2. When we combine all: $$ P(m_a, m_v | C=1) \approx \frac{1}{2\pi\sigma_p\sqrt{\sigma_a^2 + \sigma_v^2}} \cdot \exp \left( -\frac{(m_a - m_v)^2}{2(\sigma_a^2 + \sigma_v^2)} \right) $$ 4. Then we renormalize: In general we can say that $$ \int exp[-\frac{1}{2}\frac{x^2}{A^2}]=\sqrt{2\pi} A $$ Here sicnce below equation integrates to unity. This amounts to **dividing by its own integral**: and $$ x=m_a-m_v\\ A=\sigma_{av,a}^2+\sigma_{av,v}^2\\ $$ $$ \int_{-\infty}^{\infty} \exp\left[-\frac{(m_a - m_v)^2}{2(\sigma_a^2 + \sigma_v^2)}\right] d(m_a - m_v) = \sqrt{2\pi(\sigma_a^2 + \sigma_v^2)}. $$ 1. Hence the correctly normalised, “flat–prior” likelihood is $$ P(m_a, m_v \mid C = 1) = \frac{1}{\sqrt{2\pi(\sigma^2_{a} + \sigma^2_{v})}} \exp\left(-\frac{(m_a - m_v)^2}{2(\sigma^2_{a} + \sigma^2_{v})}\right) $$ </aside> <p><strong>So that integration</strong> was used twice:</p> <ul> <li>once to marginalise over sss,</li> <li>once more (conceptually) to compute the normalising constant of the Δ\DeltaΔ-Gaussian.</li> </ul> <h3 id="likelihood-of-independent-sources-c2"> <a href="#likelihood-of-independent-sources-c2" class="anchor-heading" aria-labelledby="likelihood-of-independent-sources-c2"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> <strong>Likelihood of independent sources (C=2):</strong> </h3> \[P(m_a, m_v | C=2,s_a,s_v) = P(m_a) \cdot P(m_v)\] \[= \frac{1}{2\pi \sigma_{av,a} \sigma_{av,v}}\exp\left( -\frac{(m_a - s_a)^2}{2\sigma_{av,a}^2} -\frac{(m_v - s_v)^2}{2\sigma_{av,v}^2}\right)\] <h2 id="decision"> <a href="#decision" class="anchor-heading" aria-labelledby="decision"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> <strong>Decision:</strong> </h2> <p>Finally model should compare the estimated duration for both ‘test’ and ‘standard’ intervals decision should be computed as:</p> <p>decision should be computed as:</p> \[⁍\] \[P(\text{"test longer"}) = \Phi\left(\frac{D}{\sqrt{2}\sigma_{CI}}\right)\] <p>$\hat S_{CI,t}$ The final internal estimate for the duration of the test interval and $\hat S_{CI,s}$ is the final internal estimate for the standard interval after causal inference.</p> <p>$\sigma_{CI}$ is the <strong>effective sensory noise</strong> (standard deviation) associated with the internal estimate in the causal inference model.</p> <p><img src="/assets/images/modelsOfbimodal/image 5.png" alt="image.png" /></p> </main> </div> </div> <div class="search-overlay"></div> </div> </body> </html>
